{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from math import log\n",
    "\n",
    "def split_data(data, n_tr=5, n_val=1):\n",
    "    m = n_tr+n_val+1\n",
    "    N = data.shape[0]\n",
    "    indices = np.random.permutation(N)\n",
    "    training_idx, val_idx, test_idx = indices[:int(n_tr * N/m)], indices[int(n_tr * N/m):int((n_tr+n_val) * N/m)], indices[int((n_tr+n_val) * N/m):]   \n",
    "    training, validation, test = data[training_idx,:], data[val_idx,:], data[test_idx,:]\n",
    "    return training, validation, test\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Partition(object):\n",
    "    \"\"\"\n",
    "    Object for data partition b y feature of index feature_idx\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, X, feature_idx, possible_classes):\n",
    "        self.feature_idx = feature_idx # for debug\n",
    "        self.possible_classes = possible_classes\n",
    "        self.possible_feature_values = np.unique(X[:,feature_idx])\n",
    "        self.decision_map = {value: [] for value in self.possible_feature_values}\n",
    "        self.N = len(X)\n",
    "        for x in X:\n",
    "            self.decision_map[x[feature_idx]].append(x)\n",
    "    \n",
    "    def score(self):\n",
    "        result = 0\n",
    "        for key in self.decision_map.keys():\n",
    "            key_result = 0\n",
    "            for cls in self.possible_classes:\n",
    "                p_class = sum(map(lambda x: x[-1] == cls, self.decision_map[key]))/len(self.decision_map[key])\n",
    "                if(p_class):\n",
    "                    key_result += -p_class * log(p_class)\n",
    "            result += key_result * (len(self.decision_map[key])/self.N)\n",
    "        return result\n",
    "    \n",
    "    def print_(self):\n",
    "        print('Feature index: %s' % self.feature_idx)\n",
    "        for k, v in self.decision_map.items():\n",
    "            print('Elements for value %s:' % k)\n",
    "            for row in v:\n",
    "                print('    ' + str(row))\n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_greatest_class(X):\n",
    "    count_dict = {}\n",
    "    for x in X:\n",
    "        if x[-1] in count_dict.keys():\n",
    "            count_dict[x[-1]] +=1\n",
    "        else:\n",
    "            count_dict[x[-1]] = 1\n",
    "    return sorted(count_dict.items(), key=lambda x: x[-1])[-1][0]\n",
    "\n",
    "class DecisionTree(object):\n",
    "    def __init__(self, X, possible_classes, log=False):\n",
    "        self.nodes = {}\n",
    "        self.class_ = None\n",
    "        self.classes = np.unique(X[:,-1])\n",
    "        self.possible_classes = possible_classes\n",
    "        self.classes_map = {}\n",
    "        self.X = X\n",
    "        self.log = log\n",
    "        if self.log:\n",
    "            print(X)\n",
    "            print(X[:,-1])\n",
    "        if np.all(np.all(X[:,:-1] == X[:,:-1][0,:], axis = 1)):\n",
    "            self.class_ = find_greatest_class(X)\n",
    "            return\n",
    "        if len(self.classes) == 1:\n",
    "            self.class_ = self.classes[0]\n",
    "            return\n",
    "        \n",
    "        min_value = self.find_best_partition(X)\n",
    "        self._build_node()\n",
    "        \n",
    "    def find_best_partition(self, X):\n",
    "        best_partition = None\n",
    "        min_value = 100\n",
    "        for feature_idx in range(len(X[0])-1):\n",
    "            part = Partition(X, feature_idx, self.possible_classes)\n",
    "            score = part.score()\n",
    "            if score < min_value:\n",
    "                min_value = score\n",
    "                best_partition = part\n",
    "                if self.log:\n",
    "                    print(best_partition)\n",
    "        self.partition = best_partition\n",
    "        self.feature_idx = best_partition.feature_idx\n",
    "        return min_value\n",
    "\n",
    "    def _build_node(self):\n",
    "        for k, v in self.partition.decision_map.items():\n",
    "            self.nodes[k] = DecisionTree(np.array(v), self.possible_classes)\n",
    "    \n",
    "    \n",
    "    def classify_single(self, x):        \n",
    "        if not self.class_:\n",
    "            if not hasattr(self, 'feature_idx'):\n",
    "                return self.get_class()\n",
    "            if str(x[self.feature_idx]) in self.nodes:\n",
    "                return self.nodes[str(x[self.feature_idx])].classify_single(x)\n",
    "            else:\n",
    "                return find_greatest_class(self.X)\n",
    "        else:\n",
    "            return self.class_\n",
    "    \n",
    "    def classify(self, X):\n",
    "        result = [self.classify_single(x) for x in X]\n",
    "        return sum(result[i] == X[i][-1] for i in range(len(X)))/len(X)\n",
    "    \n",
    "    def is_leaf(self):\n",
    "        return bool(self.class_)\n",
    "    \n",
    "    def print_(self):\n",
    "        if self.is_leaf():\n",
    "            print('Leaf. class: %s' % self.class_)\n",
    "        else:\n",
    "            self.partition.print_()\n",
    "            print('Children-------------------------------------\\n')\n",
    "            if self.nodes:\n",
    "                for v in self.nodes.values():\n",
    "                    v.print_()\n",
    "            print('\\n\\n\\n')\n",
    "            \n",
    "    def find_nodes_with_leafs(self):\n",
    "        res = []\n",
    "        for k, v in self.nodes.items():\n",
    "            if v.has_only_leafs():\n",
    "                res.append(v)\n",
    "            elif not v.is_leaf():\n",
    "                res.extend(v.find_nodes_with_leafs())\n",
    "        return res\n",
    "    \n",
    "    def prune(self, validation):\n",
    "        nodes_with_leafs = self.find_nodes_with_leafs()\n",
    "        for n in nodes_with_leafs:\n",
    "            acc = self.classify(validation)\n",
    "            if self.log:\n",
    "                print(n.X, find_greatest_class(n.X))\n",
    "                print(acc, self.classify(validation))\n",
    "            n.class_ = find_greatest_class(n.X)\n",
    "            if self.classify(validation) < acc:\n",
    "                n.class_ = None\n",
    "                \n",
    "    def has_only_leafs(self):\n",
    "        for k,v in self.nodes.items():\n",
    "            if not v.is_leaf():\n",
    "                return False\n",
    "        return True\n",
    "\n",
    "    def get_class(self):\n",
    "        if hasattr(self, 'class_'):\n",
    "            return self.class_\n",
    "        else:\n",
    "            print(X)\n",
    "            return find_greatest_class(X)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decision_tree_test(data):\n",
    "    train, validate, test = split_data(data, 5, 2)\n",
    "    print('Building decision Tree...')\n",
    "    d = DecisionTree(train, np.unique(data[:,-1]))\n",
    "\n",
    "    print('Score on validate after training: ', d.classify(validate))\n",
    "    print('Score on test after training: ', d.classify(test))\n",
    "    d.prune(validate)\n",
    "    print('Score on validate after pruning: ', d.classify(validate))\n",
    "    print('Score on test after training: ', d.classify(test))\n",
    "\n",
    "    \n",
    "def load_data(path, separator):\n",
    "    with open(path, 'r') as f:\n",
    "        content = f.readlines()\n",
    "        return [list(filter(lambda x: x, x.strip().split(separator))) for x in content]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_lenses(): \n",
    "    return np.roll(np.array(load_data('../lenses/lenses.data', ' ')), -1)[:,: -1]\n",
    "\n",
    "def load_hayes():\n",
    "    return np.roll(np.array(load_data('../hayes/hayes-roth.data', ',')), -1)[:,:-1]\n",
    "\n",
    "def load_mushroom():\n",
    "    return np.roll(np.array(load_data('../mushroom/agaricus-lepiota.data', ',')), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test DecisionTree on Lenses Database:\n",
      "\n",
      "Building decision Tree...\n",
      "Score on validate after training:  0.6666666666666666\n",
      "Score on test after training:  1.0\n",
      "Score on validate after pruning:  0.6666666666666666\n",
      "Score on test after training:  1.0\n",
      "\n",
      "\n",
      "\n",
      "Test DecisionTree on Hayes Database:\n",
      "\n",
      "Building decision Tree...\n",
      "Score on validate after training:  0.7272727272727273\n",
      "Score on test after training:  0.7647058823529411\n",
      "Score on validate after pruning:  0.7272727272727273\n",
      "Score on test after training:  0.7647058823529411\n",
      "\n",
      "\n",
      "\n",
      "Test DecisionTree on Mushroom Database:\n",
      "\n",
      "Building decision Tree...\n",
      "Score on validate after training:  0.816\n",
      "Score on test after training:  0.6825396825396826\n",
      "Score on validate after pruning:  0.864\n",
      "Score on test after training:  0.7301587301587301\n"
     ]
    }
   ],
   "source": [
    "print('Test DecisionTree on Lenses Database:\\n')\n",
    "decision_tree(load_lenses())\n",
    "print('\\n\\n')\n",
    "print('Test DecisionTree on Hayes Database:\\n')\n",
    "decision_tree(load_hayes())\n",
    "print('\\n\\n')\n",
    "print('Test DecisionTree on Mushroom Database:\\n')\n",
    "decision_tree_test(load_mushroom()[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
